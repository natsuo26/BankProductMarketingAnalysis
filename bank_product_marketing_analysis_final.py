# -*- coding: utf-8 -*-
"""Bank Product Marketing Analysis Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XefW2X4u3heYqfjrJCpTJI2FaY0mKlXH

Importing basic python modules to extract and visualize dataset.
"""

import os
import pandas as pd
import numpy as np
import warnings

"""Reading the dataset using pandas."""

bank = pd.read_csv('bank.csv',sep = ',')

"""Gathering information about Dataset by inspecing it."""

bank.head()

bank.info()

"""We observe that in the dataset there are **17 attributes** in total out of which **deposit** is the dependent Y variable on all rest 16 X variables. The values of deposit is either Yes or No. so later it would needed to be converted to 0 for No and 1 for Yes.

Shape of Dataset is:
"""

bank.shape

"""overall description of dataset:"""

bank.describe()

"""Let's figure out the number of unique values assigned to all attributs in dataset of 'object' type."""

for col in bank.select_dtypes(include='object').columns:
  print(col)
  print(bank[col].unique())
  print('\n')

"""# Exploratory Data Analysis
- Find Unwanted Columns
- Find Missing Values
- Find Features with one value
- Explore the Categorical Features
- Find Categorical Feature Distribution
- Relationship between Categorical Features and Label
- Explore the Numerical Features
- Find Discrete Numerical Features
- Relation between Discrete numerical Features and Labels
- Find Continous Numerical Features
- Distribution of Continous Numerical Features
- Relation between Continous numerical Features and Labels
- Find Outliers in numerical features
- Explore the Correlation between numerical features
- Find Pair Plot
- Check the Data set is balanced or not based on target values in classification
"""

df=bank

"""**1. Find Unwanted Columns**

**Take-away**:
- these is no unwanted column present in given dataset to remove

**2. Find Missing Values**
"""

features_na = [features for features in bank.columns if bank[features].isnull().sum() > 0]
for feature in features_na:
    print(feature, np.round(bank[feature].isnull().mean(), 4),  ' % missing values')
else:
    print("No missing value found")

"""**Take-away**:
- No missing value found

**3. Find Features with One Value**
"""

for column in df.columns:
    print(column,df[column].nunique())

"""**Take-away**:
- No feature with only one value

**4. Explore the Categorical Features**
"""

categorical_features=[features for features in df.columns if ((df[features].dtype=='O') & (features != 'deposit'))]
categorical_features

for feature in categorical_features:
    print('The feature is {} and number of categories are {}'.format(feature,df[feature].nunique()))

"""**Take-away**:
- there are 9 categorical features
- feature job and month has highest number of categorical values

**5. Find Categorical Feature Distribution**
"""

import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(15,80),facecolor='white')
plotnumber=1
for categorical_feature in categorical_features:
    ax = plt.subplot(12,3,plotnumber)
    sns.countplot(y=categorical_feature,data=df)
    plt.xlabel(categorical_feature)
    plt.title(categorical_feature)
    plotnumber+=1
plt.show()

"""**Take-away**:
- client with job type as management records are high in given dataset and housemaid are very less
- client who married are high in records in given dataset and divorced are less
- client whoes education background is secondary are in high numbers in given dataset
- defualt feature seems to be does not play importand role as it has value of no at high ratio to value yes which can drop
- data in month of may is high and less in dec

**6. Relationship between Categorical Features and Label**
"""

for categorical_feature in categorical_features:
    sns.catplot(x='deposit', col=categorical_feature, kind='count', data= df)
plt.show()

#Check target label split over categorical features and find the count
for categorical_feature in categorical_features:
    print(df.groupby(['deposit',categorical_feature]).size())

"""**Take-away**:
- retired client has high interest on deposit
- client who has housing loan seems to be not interested much on deposit
- if pre campagin outcome that is poutcome=success then, there is high chance of client to show interest on deposit
- in month of March, September, October and December, client show high interest to deposit
- in month of may, records are high but client interst ratio is very less

**7. Explore the Numerical Features**
"""

numerical_features = [feature for feature in df.columns if ((df[feature].dtypes != 'O') & (feature not in ['deposit']))]
print('Number of numerical variables: ', len(numerical_features))

df[numerical_features].head()

"""**Take-away**:
- there are 7 numerical features

**8. Find Discrete Numerical Features**
"""

discrete_feature=[feature for feature in numerical_features if len(df[feature].unique())<25]
print("Discrete Variables Count: {}".format(len(discrete_feature)))

"""**Take-away**:
- there is no Discrete Variables in give dataset

**9. Relation between Discrete numerical Features and Labels**
- NA

**10. Find Continous Numerical Features**
"""

continuous_features=[feature for feature in numerical_features if feature not in discrete_feature+['deposit']]
print("Continuous feature Count {}".format(len(continuous_features)))

"""**Take-away**:
- there are 7 continuous numerical features

**11. Distribution of Continous Numerical Features**
"""

plt.figure(figsize=(20,60), facecolor='white')
plotnumber =1
for continuous_feature in continuous_features:
    ax = plt.subplot(12,3,plotnumber)
    sns.distplot(df[continuous_feature])
    plt.xlabel(continuous_feature)
    plotnumber+=1
plt.show()

"""**Take-away**: 
- it seems age, days distributed normally
- balance, duration, compaign, pdays and previous heavely skewed towards left and seems to be have some outliers.

**12. Relation between Continous numerical Features and Labels**
"""

plt.figure(figsize=(20,60), facecolor='white')
plotnumber =1
for feature in continuous_features:
    ax = plt.subplot(12,3,plotnumber)
    sns.boxplot(x="deposit", y= df[feature], data=df)
    plt.xlabel(feature)
    plotnumber+=1
plt.show()

"""**Take-away**:
- client shows interest on deposit who had discussion for longer duration

**13. Find Outliers in numerical features**
"""

#boxplot on numerical features to find outliers
plt.figure(figsize=(20,60), facecolor='white')
plotnumber =1
for numerical_feature in numerical_features:
    ax = plt.subplot(12,3,plotnumber)
    sns.boxplot(df[numerical_feature])
    plt.xlabel(numerical_feature)
    plotnumber+=1
plt.show()

"""**Take-away**:
- age, balance, duration, compaign, pdays and previous has some outliers

**14. Explore the Correlation between numerical features**
"""

cor_mat=df.corr()
fig = plt.figure(figsize=(15,7))
sns.heatmap(cor_mat,annot=True)

"""**Take-away**: 
- it seems no feature is heavily correlated with other features

**15. Check the Data set is balanced or not based on target values in classification**
"""

sns.countplot(x='deposit',data=df)
plt.show()

df['deposit'].groupby(df['deposit']).count()

"""**Take-away**: 
- given dataset seems to be balanced.

# Feature Engineering 
Removing Outliers in age, balance, duration, compaign, pdays as well as dropping unwanted attributes to improve accuracy of training.
"""

df2=df.copy()

"""defaut features does not play important role"""

df2.groupby(['deposit','default']).size()

df2.drop(['default'],axis=1, inplace=True)

df2.groupby(['deposit','pdays']).size()

"""drop pdays as it has -1 value for around 40%+ """

df2.drop(['pdays'],axis=1, inplace=True)

"""remove outliers in feature age."""

df2.groupby('age',sort=True)['age'].count()

"""these can be ignored and values lies in between 18 to 95

remove outliers in feature balance.
"""

df2.groupby(['deposit','balance'],sort=True)['balance'].count()

"""these outlier should not be remove as balance goes high, client show interest on deposit

remove outliers in feature duration.
"""

df2.groupby(['deposit','duration'],sort=True)['duration'].count()

"""these outlier should not be remove as duration goes high, client show interest on deposit

remove outliers in feature campaign.
"""

df2.groupby(['deposit','campaign'],sort=True)['campaign'].count()

df3 = df2[df2['campaign'] < 33]

df3.groupby(['deposit','campaign'],sort=True)['campaign'].count()

"""remove outliers in feature previous."""

df3.groupby(['deposit','previous'],sort=True)['previous'].count()

df4 = df3[df3['previous'] < 31]

"""creating dummy categorical features for all features with multiple categorical values"""

cat_columns = ['job', 'marital', 'education', 'contact', 'month', 'poutcome']
for col in  cat_columns:
    df4 = pd.concat([df4.drop(col, axis=1),pd.get_dummies(df4[col], prefix=col, prefix_sep='_',drop_first=True, dummy_na=False)], axis=1)

bool_columns = ['housing', 'loan', 'deposit']
for col in  bool_columns:
    df4[col+'_new']=df4[col].apply(lambda x : 1 if x == 'yes' else 0)
    df4.drop(col, axis=1, inplace=True)

df4.head()

"""# Split Dataset into Training set and Test set"""

X = df4.drop(['deposit_new'],axis=1)
y = df4['deposit_new']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=0)

len(X_train)

len(X_test)

"""# Machine Learning Models and evaluation.

# **Logistic Regression**
"""

from sklearn.linear_model import LogisticRegression

logistic_model = LogisticRegression(max_iter=10000)
result = logistic_model.fit(X_train, y_train)
result.score(X_train, y_train)

predict = result.predict(X_test)

from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, predict))

from sklearn.metrics import roc_auc_score
roc_auc_score(y_test, predict)

"""# **Random Forest Classifier**"""

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier()
rfc.fit(X_train,y_train)
rfc.score(X_test,y_test)

predict_rfc=rfc.predict(X_test)

from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, predict_rfc))

from sklearn.metrics import roc_auc_score
roc_auc_score(y_test, predict_rfc)

"""# **XGBoost Classifier**"""

from xgboost import XGBClassifier
model_xgb = XGBClassifier(objective='binary:logistic',learning_rate=0.1,max_depth=10,n_estimators=100)
model_xgb.fit(X_train,y_train)
model_xgb.score(X_test,y_test)

predict_xgb=model_xgb.predict(X_test)

from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, predict_xgb))

from sklearn.metrics import roc_auc_score
roc_auc_score(y_test, predict_xgb)

"""# **Observatons and conclusions**

let's see the Confusion Matrix of all the 3 models.

# Logistic Regression
"""

from sklearn.metrics import roc_auc_score
roc_auc_score(y_test, predict)

from sklearn.metrics import confusion_matrix
lr = confusion_matrix(y_test,predict)
lr

from matplotlib import pyplot as plt
import seaborn as sn
sn.heatmap(lr, annot=True)
plt.xlabel('Predicted')
plt.ylabel('True Value')
plt.show()

"""# Random Forest Classifier"""

from sklearn.metrics import roc_auc_score
roc_auc_score(y_test, predict_rfc)

from sklearn.metrics import confusion_matrix
cx = confusion_matrix(y_test,rfc.predict( X=X_test))
cx

from matplotlib import pyplot as plt
import seaborn as sn
sn.heatmap(cx, annot=True)
plt.xlabel('Predicted')
plt.ylabel('True Value')
plt.show()

"""# XGBoost Classifier"""

from sklearn.metrics import roc_auc_score
roc_auc_score(y_test, predict_xgb)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test,model_xgb.predict(X_test))
cm

from matplotlib import pyplot as plt
import seaborn as sn
sn.heatmap(cm, annot=True)
plt.xlabel('Predicted')
plt.ylabel('True Value')
plt.show()

"""**We observe that we get the best possible score from XGBoost Classifier model.**

**so we will try to figure out the important features which this model used for prediction**
"""

headers = ["name", "score"]
values = sorted(zip(X_train.columns, model_xgb.feature_importances_), key=lambda x: x[1] * -1)
xgb_feature_importances = pd.DataFrame(values, columns = headers)

#plot feature importances
fig = plt.figure(figsize=(15,7))
x_pos = np.arange(0, len(xgb_feature_importances))
plt.bar(x_pos, xgb_feature_importances['score'])
plt.xticks(x_pos, xgb_feature_importances['name'])
plt.xticks(rotation=90)
plt.title('Feature importances (XGB)')